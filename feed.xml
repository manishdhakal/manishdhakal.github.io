<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://manishdhakal.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://manishdhakal.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-11-18T18:19:06+00:00</updated><id>https://manishdhakal.github.io/feed.xml</id><title type="html">blank</title><subtitle>Portfolio website of Manish Dhakal. </subtitle><entry><title type="html">Free Will Decoded</title><link href="https://manishdhakal.github.io/blog/2020/free-will-decoded/" rel="alternate" type="text/html" title="Free Will Decoded"/><published>2020-07-20T15:09:00+00:00</published><updated>2020-07-20T15:09:00+00:00</updated><id>https://manishdhakal.github.io/blog/2020/free-will-decoded</id><content type="html" xml:base="https://manishdhakal.github.io/blog/2020/free-will-decoded/"><![CDATA[<div class="row mt-3"> <div class="col-xs mt-2 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/free_will_decoded/free_will_poster-480.webp 480w,/assets/img/blogs/free_will_decoded/free_will_poster-800.webp 800w,/assets/img/blogs/free_will_decoded/free_will_poster-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blogs/free_will_decoded/free_will_poster.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Image src: Law of one society</figcaption> </figure> </div> </div> <h2 id="what-is-free-will">What is Free Will?</h2> <p>Free will is the ability to make free decisions that are not predetermined in any manner. The term “free will” has been around for two millennia. Free will supports the laws of randomness. Traditionally, people thought that the universe is a blend of randomness — what is going to happen in the future is random.</p> <p>Philosophically speaking, free will exists, but science denies that. Free will is just an illusion. Science follows the laws of determinism (ie. events, including moral choices, are completely determined by previously existing causes). You reading this article was determined during the time of the <b>Big Bang</b>. According to the laws of physics, any event is determined by the things before it. Just because we don’t know what is going to happen in the future, we can not say determinism does not exist.</p> <div class="row mt-3"> <div class="col-xs mt-2 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/free_will_decoded/human_mind-480.webp 480w,/assets/img/blogs/free_will_decoded/human_mind-800.webp 800w,/assets/img/blogs/free_will_decoded/human_mind-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blogs/free_will_decoded/human_mind.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Image src: wallpaperflare.com</figcaption> </figure> </div> </div> <p>The universe is a vast mass of arbitrarily flowing atoms. Our brain is also a composition of atoms, so they are subject to the laws of physics. The electric signals flowing from one neuron to another are also bound by these laws. It’s just that the amount of calculation involving the thought process inside the brain is so intricate that no one has been able to calculate it till now.</p> <p>Suppose there is a hungry person on the street. You might think the decision of whether or not to help the person is your free choice. But actually, it is your morality that drives your decision. Your morality is derived from the environmental constraints you are brought up in as well as your parents’ morality. Your parents’ morality is affected by their parents’ morality and so on. It all traces back to the beginning of matter — billions of years ago. You can also say, let’s flip a coin to decide on this matter, but remember that the output of the flip is also not random.</p> <p>GAN is the technology in the field of Neural Network innovated by Ian Goodfellow and his friends. <a href="https://arxiv.org/abs/1609.04802"> SRGAN </a> is the method by which we can increase the resolution of any image.</p> <p>It contains basically two parts: a <b>Generator</b> and a <b>Discriminator</b>. The generator produces refined output data from given input noise. Discriminator receives two types of data: one is the real-world data and another is the generated output from the generator. For discriminator, real data has label ‘1’ and generated data has label ‘0’. We can take the analogy of the generator as an <b>artist</b> and the discriminator as a <b>critic</b>. Artists create an art form that is judged by the critic.</p> <h2 id="block-universe">Block Universe</h2> <div class="row mt-3"> <div class="col-xs mt-2 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/free_will_decoded/block_universe-480.webp 480w,/assets/img/blogs/free_will_decoded/block_universe-800.webp 800w,/assets/img/blogs/free_will_decoded/block_universe-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blogs/free_will_decoded/block_universe.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Image src: BBC Reel</figcaption> </figure> </div> </div> <p>According to the theory of Block Universe, the universe is a giant block of all events that took place at any instance of time. The past, present, and future all co-exist in that block. The block has four dimensions — three spatial dimensions(length, width, and height) and a temporal dimension of time. This theory supports the law of determinism.</p> <p>Let’s consider the block to be a loaf of bread, and a slice of the bread has all the things in the universe at any instance of time. In the block universe, time never passes. All the events that had happened and will happen are already there. There is no universal now moment in the block. The concept of now is an illusion. We just experience different slices at any moment. All the events that happened from the Big Bang to the end of the universe are already there in the block.</p> <p>It also supports the concept of a <a href="https://www.space.com/32728-parallel-universes.html"> Parallel Universe </a>; just consider multiple loaves of bread. In one loaf, you exist as you do now. In another, you may have never been born. On the another, your parents have never met. In another, the earth may not exist at all, and so on and so forth.</p> <h2 id="can-we-predict-the-future">Can we predict the future?</h2> <div class="row mt-3"> <div class="col-xs mt-2 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/free_will_decoded/yes_but_no-480.webp 480w,/assets/img/blogs/free_will_decoded/yes_but_no-800.webp 800w,/assets/img/blogs/free_will_decoded/yes_but_no-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blogs/free_will_decoded/yes_but_no.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Since there is no free will and the universe is not random, we should be able to predict the future, right? It is far more difficult, nearly impossible, to compute such complex calculations with present computational power. We need billions, trillions, or maybe infinite—we don’t know how many—parameters to start the calculation. The equation for such calculation must be accurate and precise. Maybe in the distant future, we might be able to calculate it.</p> <h3 id="can-it-have-a-negative-impact">Can it have a negative impact?</h3> <p>We might think that we end up with a fixed result even though we make so many efforts. It is better for us that we cannot see the future. For all practical purposes, we are making free choices even though it is an illusion. Even after writing this much to you, I will not be depressed that I have no free will. My mind will be unconsciously making choices for me my whole life.</p> <p>Crimes are still punishable, though. We can not forgive a criminal saying that it was determined that the person would commit the crime. If he was determined to commit a crime then, he was also determined to be punished. This helps in shaping the morality of others and the criminal as mentioned above.</p> <h2 id="references">References</h2> <ul> <li><a href="https://www.bbc.com/reel/playlist/free-will?vpid=p086tg3m">BBC-Reel on Free Will </a></li> <li><a href="https://www.abc.net.au/news/science/2018-09-02/block-universe-theory-time-past-present-future-travel/10178386">Block Universe </a></li> </ul>]]></content><author><name></name></author><category term="non-technical-posts"/><category term="free-will"/><summary type="html"><![CDATA[The universe already knew that you would be reading this article.]]></summary></entry><entry><title type="html">Super Resolution with GAN (SRGAN) using Keras API</title><link href="https://manishdhakal.github.io/blog/2020/super-resolution/" rel="alternate" type="text/html" title="Super Resolution with GAN (SRGAN) using Keras API"/><published>2020-06-19T15:09:00+00:00</published><updated>2020-06-19T15:09:00+00:00</updated><id>https://manishdhakal.github.io/blog/2020/super-resolution</id><content type="html" xml:base="https://manishdhakal.github.io/blog/2020/super-resolution/"><![CDATA[<div class="row mt-3"> <div class="col-xs mt-2 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/super_resolution/GAN-480.webp 480w,/assets/img/blogs/super_resolution/GAN-800.webp 800w,/assets/img/blogs/super_resolution/GAN-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blogs/super_resolution/GAN.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Image src: neuralnet.ai</figcaption> </figure> </div> </div> <p>This blog allows us to implement super-resolution in Python to increase the resolution of 25X25 images by 4X4.</p> <h2 id="prior-knowledge">Prior Knowledge</h2> <ul> <li>Neural Networks</li> <li>Python</li> <li>Keras</li> </ul> <h2 id="generative-adverserial-networks">Generative Adverserial Networks</h2> <p>GAN is the technology in the field of Neural Network innovated by Ian Goodfellow and his friends. <a href="https://arxiv.org/abs/1609.04802"> SRGAN </a> is the method by which we can increase the resolution of any image.</p> <div class="row mt-3"> <div class="col-xs mt-2 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/super_resolution/GAN_working-480.webp 480w,/assets/img/blogs/super_resolution/GAN_working-800.webp 800w,/assets/img/blogs/super_resolution/GAN_working-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blogs/super_resolution/GAN_working.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Image src: mc.ai</figcaption> </figure> </div> </div> <p>It contains basically two parts: a <b>Generator</b> and a <b>Discriminator</b>. The generator produces refined output data from given input noise. Discriminator receives two types of data: one is the real-world data and another is the generated output from the generator. For discriminator, real data has label ‘1’ and generated data has label ‘0’. We can take the analogy of the generator as an <b>artist</b> and the discriminator as a <b>critic</b>. Artists create an art form that is judged by the critic.</p> <div class="row mt-3"> <div class="col-xs mt-2 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/super_resolution/GAN_artist_critic-480.webp 480w,/assets/img/blogs/super_resolution/GAN_artist_critic-800.webp 800w,/assets/img/blogs/super_resolution/GAN_artist_critic-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blogs/super_resolution/GAN_artist_critic.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Image src: rhyme.com</figcaption> </figure> </div> </div> <p>As the generator improves with training, the discriminator’s performance gets worse because the discriminator can’t easily tell the difference between real and fake. Theoretically, the discriminator will have 50% accuracy just like the flip of a coin.</p> <blockquote> <p>So our motto is to decrease the accuracy of the people who judge us and focus on our artwork.</p> </blockquote> <h2 id="structure-of-srgan">Structure of SRGAN</h2> <div class="row mt-3"> <div class="col-xs mt-2 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/super_resolution/SRGAN-480.webp 480w,/assets/img/blogs/super_resolution/SRGAN-800.webp 800w,/assets/img/blogs/super_resolution/SRGAN-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blogs/super_resolution/SRGAN.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Image src: arxiv.org/pdf/1609.04802.pdf || Architecture of Generator and Discriminator Network with corresponding kernel size (k), number of feature maps (n) and stride (s) indicated for each convolutional layer.</figcaption> </figure> </div> </div> <h3 id="alternate-training">Alternate Training</h3> <p>The generator and discriminator are trained differently. The first discriminator is trained for one or more epochs and the generator is also trained for one or more epochs then one cycle is said to be completed. The pre-trained VGG19 model is used to extract features from the image while training.</p> <p>While training the generator the parameters of the discriminator are frozen or else the model would be hitting a moving target and never converges.</p> <h2 id="code">Code</h2> <h4 id="import-necessary-dependencies">Import necessary dependencies</h4> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">PReLU</span><span class="p">,</span><span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">UpSampling2D</span><span class="p">,</span> <span class="n">LeakyReLU</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">add</span>
</code></pre></div></div> <h4 id="some-of-the-necessary-variables">Some of the necessary variables</h4> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr_ip</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">hr_ip</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">train_lr</span><span class="p">,</span><span class="n">train_hr</span> <span class="o">=</span> <span class="c1">#training images arrays normalized between 0 &amp; 1
</span><span class="n">test_lr</span><span class="p">,</span> <span class="n">test_hr</span> <span class="o">=</span> <span class="c1"># testing images arrays normalized between 0 &amp; 1
</span></code></pre></div></div> <h4 id="define-generator">Define Generator</h4> <p>We have to define a function to return the generator model which is used to produce the high-resolution image. Residual block is the function which returns the addition of the input layer and the final layer.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Residual block
</span><span class="k">def</span> <span class="nf">res_block</span><span class="p">(</span><span class="n">ip</span><span class="p">):</span>
    
    <span class="n">res_model</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span> <span class="o">=</span> <span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">)(</span><span class="n">ip</span><span class="p">)</span>
    <span class="n">res_model</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">(</span><span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)(</span><span class="n">res_model</span><span class="p">)</span>
    <span class="n">res_model</span> <span class="o">=</span> <span class="nc">PReLU</span><span class="p">(</span><span class="n">shared_axes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])(</span><span class="n">res_model</span><span class="p">)</span>
    
    <span class="n">res_model</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span> <span class="o">=</span> <span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">)(</span><span class="n">res_model</span><span class="p">)</span>
    <span class="n">res_model</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">(</span><span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)(</span><span class="n">res_model</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="nf">add</span><span class="p">([</span><span class="n">ip</span><span class="p">,</span><span class="n">res_model</span><span class="p">])</span>

<span class="c1"># Upscale the image 2x
</span><span class="k">def</span> <span class="nf">upscale_block</span><span class="p">(</span><span class="n">ip</span><span class="p">):</span>
    
    <span class="n">up_model</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">)(</span><span class="n">ip</span><span class="p">)</span>
    <span class="n">up_model</span> <span class="o">=</span> <span class="nc">UpSampling2D</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">up_model</span><span class="p">)</span>
    <span class="n">up_model</span> <span class="o">=</span> <span class="nc">PReLU</span><span class="p">(</span><span class="n">shared_axes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])(</span><span class="n">up_model</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">up_model</span>

<span class="c1"># Generator Model
</span><span class="k">def</span> <span class="nf">create_gen</span><span class="p">(</span><span class="n">gen_ip</span><span class="p">,</span> <span class="n">num_res_block</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">)(</span><span class="n">gen_ip</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="nc">PReLU</span><span class="p">(</span><span class="n">shared_axes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])(</span><span class="n">layers</span><span class="p">)</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">layers</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_res_block</span><span class="p">):</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="nf">res_block</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">)(</span><span class="n">layers</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">(</span><span class="n">momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">layers</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="nf">add</span><span class="p">([</span><span class="n">layers</span><span class="p">,</span><span class="n">temp</span><span class="p">])</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="nf">upscale_block</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="nf">upscale_block</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
    <span class="n">op</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">)(</span><span class="n">layers</span><span class="p">)</span>
    <span class="k">return</span> <span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">gen_ip</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">op</span><span class="p">)</span>
</code></pre></div></div> <h4 id="define-discriminator">Define Discriminator</h4> <p>This block of code defines the structure of the discriminator model, and all of the layers involved to distinguish between real and generated images. As we go deeper, after every 2 layers the number of filters increases by twice.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Small block inside the discriminator
</span><span class="k">def</span> <span class="nf">discriminator_block</span><span class="p">(</span><span class="n">ip</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    
    <span class="n">disc_model</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">)(</span><span class="n">ip</span><span class="p">)</span>
    <span class="n">disc_model</span> <span class="o">=</span> <span class="nc">LeakyReLU</span><span class="p">(</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span> <span class="p">)(</span><span class="n">disc_model</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bn</span><span class="p">:</span>
        <span class="n">disc_model</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">(</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.8</span> <span class="p">)(</span><span class="n">disc_model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">disc_model</span>

<span class="c1"># Discriminator Model
</span><span class="k">def</span> <span class="nf">create_disc</span><span class="p">(</span><span class="n">disc_ip</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="mi">64</span>
    
    <span class="n">d1</span> <span class="o">=</span> <span class="nf">discriminator_block</span><span class="p">(</span><span class="n">disc_ip</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">d2</span> <span class="o">=</span> <span class="nf">discriminator_block</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">d3</span> <span class="o">=</span> <span class="nf">discriminator_block</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">df</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">d4</span> <span class="o">=</span> <span class="nf">discriminator_block</span><span class="p">(</span><span class="n">d3</span><span class="p">,</span> <span class="n">df</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">d5</span> <span class="o">=</span> <span class="nf">discriminator_block</span><span class="p">(</span><span class="n">d4</span><span class="p">,</span> <span class="n">df</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">d6</span> <span class="o">=</span> <span class="nf">discriminator_block</span><span class="p">(</span><span class="n">d5</span><span class="p">,</span> <span class="n">df</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">d7</span> <span class="o">=</span> <span class="nf">discriminator_block</span><span class="p">(</span><span class="n">d6</span><span class="p">,</span> <span class="n">df</span><span class="o">*</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">d8</span> <span class="o">=</span> <span class="nf">discriminator_block</span><span class="p">(</span><span class="n">d7</span><span class="p">,</span> <span class="n">df</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="n">d8_5</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()(</span><span class="n">d8</span><span class="p">)</span>
    <span class="n">d9</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">df</span><span class="o">*</span><span class="mi">16</span><span class="p">)(</span><span class="n">d8_5</span><span class="p">)</span>
    <span class="n">d10</span> <span class="o">=</span> <span class="nc">LeakyReLU</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">d9</span><span class="p">)</span>
    <span class="n">validity</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">sigmoid</span><span class="sh">'</span><span class="p">)(</span><span class="n">d10</span><span class="p">)</span>
    <span class="k">return</span> <span class="nc">Model</span><span class="p">(</span><span class="n">disc_ip</span><span class="p">,</span> <span class="n">validity</span><span class="p">)</span>
</code></pre></div></div> <h4 id="vgg19-model">VGG19 Model</h4> <p>In this code block, we use the VGG19 model trained with an image-net database to extract the features, this model is frozen later so that parameters won’t get updated.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">keras.applications</span> <span class="kn">import</span> <span class="n">VGG19</span>
<span class="c1"># Build the VGG19 model upto 10th layer 
# Used to extract the features of high res imgaes
</span><span class="k">def</span> <span class="nf">build_vgg</span><span class="p">():</span>
    <span class="n">vgg</span> <span class="o">=</span> <span class="nc">VGG19</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="sh">"</span><span class="s">imagenet</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">vgg</span><span class="p">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">vgg</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">9</span><span class="p">].</span><span class="n">output</span><span class="p">]</span>
    <span class="n">img</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">hr_shape</span><span class="p">)</span>
    <span class="n">img_features</span> <span class="o">=</span> <span class="nf">vgg</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="k">return</span> <span class="nc">Model</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">img_features</span><span class="p">)</span>
</code></pre></div></div> <h4 id="combined-model">Combined Model</h4> <p>Now, we attach both the generator and discriminator model. The model obtained from this is used only to train the generator model. While training this combined model we have to freeze the discriminator in each epoch.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Attach the generator and discriminator
</span><span class="k">def</span> <span class="nf">create_comb</span><span class="p">(</span><span class="n">gen_model</span><span class="p">,</span> <span class="n">disc_model</span><span class="p">,</span> <span class="n">vgg</span><span class="p">,</span> <span class="n">lr_ip</span><span class="p">,</span> <span class="n">hr_ip</span><span class="p">):</span>
    <span class="n">gen_img</span> <span class="o">=</span> <span class="nf">gen_model</span><span class="p">(</span><span class="n">lr_ip</span><span class="p">)</span>
    <span class="n">gen_features</span> <span class="o">=</span> <span class="nf">vgg</span><span class="p">(</span><span class="n">gen_img</span><span class="p">)</span>
    <span class="n">disc_model</span><span class="p">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">validity</span> <span class="o">=</span> <span class="nf">disc_model</span><span class="p">(</span><span class="n">gen_img</span><span class="p">)</span>
    <span class="k">return</span> <span class="nc">Model</span><span class="p">([</span><span class="n">lr_ip</span><span class="p">,</span> <span class="n">hr_ip</span><span class="p">],[</span><span class="n">validity</span><span class="p">,</span><span class="n">gen_features</span><span class="p">])</span>
</code></pre></div></div> <h4 id="declare-models">Declare models</h4> <p>Then, we declare generator, discriminator, and vgg models. Those models will be used as arguments for the combined model.</p> <blockquote> <p>Any changes in the smaller models inside the combined model also affect the model outside like weight updates, freezing the model, etc.</p> </blockquote> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generator</span> <span class="o">=</span> <span class="nf">create_gen</span><span class="p">(</span><span class="n">lr_ip</span><span class="p">)</span>
<span class="n">discriminator</span> <span class="o">=</span> <span class="nf">create_disc</span><span class="p">(</span><span class="n">hr_ip</span><span class="p">)</span>
<span class="n">discriminator</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">binary_crossentropy</span><span class="sh">"</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="sh">"</span><span class="s">adam</span><span class="sh">"</span><span class="p">,</span>      
  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">])</span>
<span class="n">vgg</span> <span class="o">=</span> <span class="nf">build_vgg</span><span class="p">()</span>
<span class="n">vgg</span><span class="p">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="bp">False</span>
<span class="n">gan_model</span> <span class="o">=</span> <span class="nf">create_comb</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">discriminator</span><span class="p">,</span> <span class="n">vgg</span><span class="p">,</span> <span class="n">lr_ip</span><span class="p">,</span> <span class="n">hr_ip</span><span class="p">)</span>
<span class="n">gan_model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">binary_crossentropy</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">mse</span><span class="sh">"</span><span class="p">],</span> <span class="n">loss_weights</span><span class="o">=</span>
  <span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">optimizer</span><span class="o">=</span><span class="sh">"</span><span class="s">adam</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h4 id="sample-the-training-data-in-small-batches">Sample the training data in small batches</h4> <p>As the training set is too large, we need to sample the images into small batches to avoid <b>Resource Exhausted Error</b>. A resource such as RAM will not be enough to train all the images at once.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">train_lr_batches</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_hr_batches</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="n">train_hr</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)):</span>
    <span class="n">start_idx</span> <span class="o">=</span> <span class="n">it</span> <span class="o">*</span> <span class="n">batch_size</span>
    <span class="n">end_idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span>
    <span class="n">train_hr_batches</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">train_hr</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">])</span>
    <span class="n">train_lr_batches</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">train_lr</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">])</span>
<span class="n">train_lr_batches</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">train_lr_batches</span><span class="p">)</span>
<span class="n">train_hr_batches</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">train_hr_batches</span><span class="p">)</span>
</code></pre></div></div> <h4 id="training-the-model">Training the model</h4> <p>This block is the core of the whole program. Here we train the discriminator and generator in the alternating method as mentioned above. As of now, the discriminator is frozen, do not forget to unfreeze before and freeze after training the discriminator, which is given in the code below.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">gen_label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">real_label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">g_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">d_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">train_hr_batches</span><span class="p">)):</span>
        <span class="n">lr_imgs</span> <span class="o">=</span> <span class="n">train_lr_batches</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
        <span class="n">hr_imgs</span> <span class="o">=</span> <span class="n">train_hr_batches</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
        <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">.</span><span class="nf">predict_on_batch</span><span class="p">(</span><span class="n">lr_imgs</span><span class="p">)</span>
        <span class="c1">#Dont forget to make the discriminator trainable
</span>        <span class="n">discriminator</span><span class="p">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="bp">True</span>
        
        <span class="c1">#Train the discriminator
</span>        <span class="n">d_loss_gen</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">.</span><span class="nf">train_on_batch</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">,</span>
          <span class="n">gen_label</span><span class="p">)</span>
        <span class="n">d_loss_real</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">.</span><span class="nf">train_on_batch</span><span class="p">(</span><span class="n">hr_imgs</span><span class="p">,</span>
          <span class="n">real_label</span><span class="p">)</span>
        <span class="n">discriminator</span><span class="p">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="n">d_loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">d_loss_gen</span><span class="p">,</span> <span class="n">d_loss_real</span><span class="p">)</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="n">vgg</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">hr_imgs</span><span class="p">)</span>
        
        <span class="c1">#Train the generator
</span>        <span class="n">g_loss</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">gan_model</span><span class="p">.</span><span class="nf">train_on_batch</span><span class="p">([</span><span class="n">lr_imgs</span><span class="p">,</span> <span class="n">hr_imgs</span><span class="p">],</span> 
          <span class="p">[</span><span class="n">real_label</span><span class="p">,</span> <span class="n">image_features</span><span class="p">])</span>
        
        <span class="n">d_losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">d_loss</span><span class="p">)</span>
        <span class="n">g_losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">g_loss</span><span class="p">)</span>
    <span class="n">g_losses</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">g_losses</span><span class="p">)</span>
    <span class="n">d_losses</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">d_losses</span><span class="p">)</span>
    
    <span class="n">g_loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">g_losses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">g_losses</span><span class="p">)</span>
    <span class="n">d_loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">d_losses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">d_losses</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">epoch:</span><span class="sh">"</span><span class="p">,</span> <span class="n">e</span><span class="o">+</span><span class="mi">1</span> <span class="p">,</span><span class="sh">"</span><span class="s">g_loss:</span><span class="sh">"</span><span class="p">,</span> <span class="n">g_loss</span><span class="p">,</span> <span class="sh">"</span><span class="s">d_loss:</span><span class="sh">"</span><span class="p">,</span> <span class="n">d_loss</span><span class="p">)</span>
</code></pre></div></div> <h4 id="evaluate-the-model">Evaluate the model</h4> <p>Hereby, we calculate the performance of the generator with the test dataset. The loss may be a little larger than with the training dataset, but do not worry as long as the difference is small.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">test_lr</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">vgg</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">test_hr</span><span class="p">)</span>
<span class="nb">eval</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">gan_model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">([</span><span class="n">test_lr</span><span class="p">,</span> <span class="n">test_hr</span><span class="p">],</span> <span class="p">[</span><span class="n">label</span><span class="p">,</span><span class="n">test_features</span><span class="p">])</span>
</code></pre></div></div> <h4 id="predict-the-output">Predict the output</h4> <p>We can generate high-resolution images with a generator model.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_prediction</span> <span class="o">=</span> <span class="n">generator</span><span class="p">.</span><span class="nf">predict_on_batch</span><span class="p">(</span><span class="n">test_lr</span><span class="p">)</span>
</code></pre></div></div> <p>The output is quite amazing…</p> <div class="row mt-3"> <div class="col-xs mt-2 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/super_resolution/results-480.webp 480w,/assets/img/blogs/super_resolution/results-800.webp 800w,/assets/img/blogs/super_resolution/results-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blogs/super_resolution/results.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Results of the experiment</figcaption> </figure> </div> </div> <h2 id="tips">Tips</h2> <ul> <li>Always remember which model to make trainable or not.</li> <li>While training the generator use the label value as one.</li> <li>It is better to use images larger than 25x25 as they have more details for generated images.</li> <li>Do not forget to normalize the NumPy object dataset between 0 and 1 to reach minimal loss faster.</li> </ul> <h2 id="references">References</h2> <ul> <li>Jason Brownlee. 2019. Generative Adversarial Networks with Python</li> <li>Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network — https://arxiv.org/abs/1609.04802</li> </ul>]]></content><author><name></name></author><category term="technical-posts"/><category term="computer-vision"/><category term="super-resolution"/><summary type="html"><![CDATA[Implemented the code to increase the resolution of the 25x25 images 4x4.]]></summary></entry></feed>